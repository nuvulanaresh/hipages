from pyspark.sql.types import *
from pyspark.sql.functions import *
jsonpath="/FileStore/tables/source_event_data.json"
urldf=(spark.read
      .option("inferSchema","true")
      .option("header","false")
      .json(jsonpath)
      .select(col("event_id"),col("user.id").alias("user_id"),col("action").alias("activity"),"url",col("timestamp").alias("time_stamp"))
      .withColumn("url_level1",concat(split(("url"),'\\.').getItem(1),lit('.'),split(("url"),'\\.').getItem(2)))\
      .withColumn("url_sub_level",split(("url"),'\\.').getItem(3))
      .withColumn("url_level2",split(("url_sub_level"),"/").getItem(1))
      .withColumn("url_level3",split(("url_sub_level"),"/").getItem(2))
      .select("user_id","time_stamp","url_level1","url_level2","url_level3","activity")
      )
urldf.show(50,False)
